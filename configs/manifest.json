{
    "package_name": "bithoven/llm-provider-ollama",
    "version": "0.1.0",
    "provider": "ollama",
    "description": "Ollama local LLM configurations - Run powerful models on your own hardware",
    "created_at": "2025-12-12T04:00:00Z",
    "updated_at": "2025-12-12T04:00:00Z",
    "author": "Bithoven Team",
    "homepage": "https://github.com/bithoven/llm-provider-ollama",
    "license": "MIT",
    "configurations": [
        {
            "file": "llama-3.3-70b.json",
            "name": "Llama 3.3 70B",
            "slug": "llama-3-3-70b",
            "recommended": true,
            "tags": ["general-purpose", "large-model", "production-ready"]
        },
        {
            "file": "llama-3.2-3b.json",
            "name": "Llama 3.2 3B",
            "slug": "llama-3-2-3b",
            "recommended": true,
            "tags": ["lightweight", "fast", "cost-effective"]
        },
        {
            "file": "llama-3.2-1b.json",
            "name": "Llama 3.2 1B",
            "slug": "llama-3-2-1b",
            "recommended": false,
            "tags": ["ultra-lightweight", "experimental"]
        },
        {
            "file": "llama-3.1-8b.json",
            "name": "Llama 3.1 8B",
            "slug": "llama-3-1-8b",
            "recommended": true,
            "tags": ["balanced", "mid-size", "versatile"]
        },
        {
            "file": "llama-3.1-70b.json",
            "name": "Llama 3.1 70B",
            "slug": "llama-3-1-70b",
            "recommended": false,
            "tags": ["large-model", "high-quality"]
        },
        {
            "file": "mistral-7b.json",
            "name": "Mistral 7B",
            "slug": "mistral-7b",
            "recommended": true,
            "tags": ["efficient", "instruction-tuned", "production-ready"]
        },
        {
            "file": "mistral-nemo-12b.json",
            "name": "Mistral Nemo 12B",
            "slug": "mistral-nemo-12b",
            "recommended": false,
            "tags": ["mid-size", "advanced"]
        },
        {
            "file": "codellama-70b.json",
            "name": "CodeLlama 70B",
            "slug": "codellama-70b",
            "recommended": true,
            "tags": ["code-generation", "large-model", "expert"]
        },
        {
            "file": "codellama-34b.json",
            "name": "CodeLlama 34B",
            "slug": "codellama-34b",
            "recommended": false,
            "tags": ["code-generation", "mid-size"]
        },
        {
            "file": "codellama-13b.json",
            "name": "CodeLlama 13B",
            "slug": "codellama-13b",
            "recommended": false,
            "tags": ["code-generation", "lightweight"]
        },
        {
            "file": "gemma-2-27b.json",
            "name": "Gemma 2 27B",
            "slug": "gemma-2-27b",
            "recommended": true,
            "tags": ["google", "efficient", "production-ready"]
        },
        {
            "file": "gemma-2-9b.json",
            "name": "Gemma 2 9B",
            "slug": "gemma-2-9b",
            "recommended": true,
            "tags": ["google", "lightweight", "fast"]
        },
        {
            "file": "gemma-2-2b.json",
            "name": "Gemma 2 2B",
            "slug": "gemma-2-2b",
            "recommended": false,
            "tags": ["google", "ultra-lightweight"]
        },
        {
            "file": "phi-3-mini.json",
            "name": "Phi-3 Mini",
            "slug": "phi-3-mini",
            "recommended": true,
            "tags": ["microsoft", "compact", "efficient"]
        },
        {
            "file": "phi-3-small.json",
            "name": "Phi-3 Small",
            "slug": "phi-3-small",
            "recommended": false,
            "tags": ["microsoft", "balanced"]
        },
        {
            "file": "phi-3-medium.json",
            "name": "Phi-3 Medium",
            "slug": "phi-3-medium",
            "recommended": false,
            "tags": ["microsoft", "advanced"]
        },
        {
            "file": "deepseek-coder-6.7b.json",
            "name": "DeepSeek Coder 6.7B",
            "slug": "deepseek-coder-6-7b",
            "recommended": true,
            "tags": ["code-generation", "specialized", "efficient"]
        },
        {
            "file": "deepseek-coder-33b.json",
            "name": "DeepSeek Coder 33B",
            "slug": "deepseek-coder-33b",
            "recommended": false,
            "tags": ["code-generation", "specialized", "large-model"]
        }
    ],
    "requirements": {
        "llm-manager": ">=0.4.0",
        "ollama": ">=0.1.0"
    },
    "tags": ["local", "privacy", "offline-capable", "open-source", "self-hosted"]
}
