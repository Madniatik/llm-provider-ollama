{
    "name": "bithoven/llm-provider-ollama",
    "description": "Ollama provider package for Bithoven LLM Manager - Local LLM models with full ServiceProvider integration",
    "type": "library",
    "license": "MIT",
    "version": "0.2.0",
    "keywords": [
        "bithoven",
        "llm",
        "ollama",
        "llama",
        "mistral",
        "local-models",
        "ai",
        "machine-learning",
        "configuration"
    ],
    "authors": [
        {
            "name": "Bithoven Team",
            "email": "dev@bithoven.dev"
        }
    ],
    "require": {
        "php": "^8.1|^8.2|^8.3",
        "illuminate/support": "^10.0|^11.0",
        "illuminate/http": "^10.0|^11.0",
        "illuminate/database": "^10.0|^11.0",
        "nesbot/carbon": "^2.0|^3.0"
    },
    "autoload": {
        "psr-4": {
            "Bithoven\\LLMProviderOllama\\": "src/"
        }
    },
    "autoload-dev": {
        "psr-4": {
            "Tests\\": "tests/"
        }
    },
    "minimum-stability": "dev",
    "prefer-stable": true,
    "extra": {
        "laravel": {
            "providers": [
                "Bithoven\\LLMProviderOllama\\OllamaServiceProvider"
            ]
        },
        "bithoven": {
            "type": "llm-provider-package",
            "provider": "ollama",
            "configs-path": "configs/",
            "prompts-path": "prompts/"
        }
    }
}
